{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebfc3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: torch.Size([60000, 28, 28])\n",
      "train_labels: torch.Size([60000])\n",
      "test_data: torch.Size([10000, 28, 28])\n",
      "Net(\n",
      "  (linear_0): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (linear_1): Linear(in_features=500, out_features=128, bias=True)\n",
      "  (linear_2): Linear(in_features=128, out_features=50, bias=True)\n",
      "  (linear_3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (act): ReLU()\n",
      ")\n",
      "The model has 463,588 trainable parameters\n",
      "epoch 1\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n",
      "Train Loss: 0.006123, Acc: 0.884200\n",
      "Test Loss: 0.003717, Acc: 0.932300\n",
      "epoch 2\n",
      "Train Loss: 0.003287, Acc: 0.940317\n",
      "Test Loss: 0.002973, Acc: 0.943400\n",
      "epoch 3\n",
      "Train Loss: 0.002785, Acc: 0.949967\n",
      "Test Loss: 0.002301, Acc: 0.957600\n",
      "epoch 4\n",
      "Train Loss: 0.002494, Acc: 0.954850\n",
      "Test Loss: 0.002483, Acc: 0.953700\n",
      "epoch 5\n",
      "Train Loss: 0.002362, Acc: 0.958350\n",
      "Test Loss: 0.002387, Acc: 0.956400\n",
      "epoch 6\n",
      "Train Loss: 0.002238, Acc: 0.960017\n",
      "Test Loss: 0.001929, Acc: 0.966400\n",
      "epoch 7\n",
      "Train Loss: 0.002182, Acc: 0.960800\n",
      "Test Loss: 0.002106, Acc: 0.961700\n",
      "epoch 8\n",
      "Train Loss: 0.002146, Acc: 0.962833\n",
      "Test Loss: 0.002208, Acc: 0.959100\n",
      "epoch 9\n",
      "Train Loss: 0.002101, Acc: 0.963400\n",
      "Test Loss: 0.001947, Acc: 0.967100\n",
      "epoch 10\n",
      "Train Loss: 0.002086, Acc: 0.963233\n",
      "Test Loss: 0.002117, Acc: 0.960600\n",
      "epoch 11\n",
      "Train Loss: 0.002064, Acc: 0.964433\n",
      "Test Loss: 0.001906, Acc: 0.968500\n",
      "epoch 12\n",
      "Train Loss: 0.002066, Acc: 0.963417\n",
      "Test Loss: 0.001923, Acc: 0.964900\n",
      "epoch 13\n",
      "Train Loss: 0.002047, Acc: 0.963850\n",
      "Test Loss: 0.001991, Acc: 0.964800\n",
      "epoch 14\n",
      "Train Loss: 0.002020, Acc: 0.964750\n",
      "Test Loss: 0.002252, Acc: 0.957800\n",
      "epoch 15\n",
      "Train Loss: 0.002014, Acc: 0.964067\n",
      "Test Loss: 0.001910, Acc: 0.964800\n",
      "epoch 16\n",
      "Train Loss: 0.001998, Acc: 0.965217\n",
      "Test Loss: 0.001910, Acc: 0.966500\n",
      "epoch 17\n",
      "Train Loss: 0.002009, Acc: 0.965050\n",
      "Test Loss: 0.001919, Acc: 0.966300\n",
      "epoch 18\n",
      "Train Loss: 0.001976, Acc: 0.966167\n",
      "Test Loss: 0.001985, Acc: 0.965000\n",
      "epoch 19\n",
      "Train Loss: 0.002009, Acc: 0.965383\n",
      "Test Loss: 0.001897, Acc: 0.965900\n",
      "epoch 20\n",
      "Train Loss: 0.002003, Acc: 0.964750\n",
      "Test Loss: 0.001961, Acc: 0.963600\n",
      "epoch 21\n",
      "Train Loss: 0.001964, Acc: 0.965833\n",
      "Test Loss: 0.001858, Acc: 0.966300\n",
      "epoch 22\n",
      "Train Loss: 0.001988, Acc: 0.965400\n",
      "Test Loss: 0.001992, Acc: 0.963700\n",
      "epoch 23\n",
      "Train Loss: 0.001942, Acc: 0.966633\n",
      "Test Loss: 0.001904, Acc: 0.966300\n",
      "epoch 24\n",
      "Train Loss: 0.001960, Acc: 0.966183\n",
      "Test Loss: 0.002201, Acc: 0.960700\n",
      "epoch 25\n",
      "Train Loss: 0.001969, Acc: 0.966083\n",
      "Test Loss: 0.001857, Acc: 0.965400\n",
      "epoch 26\n",
      "Train Loss: 0.001968, Acc: 0.966283\n",
      "Test Loss: 0.001953, Acc: 0.962700\n",
      "epoch 27\n",
      "Train Loss: 0.001951, Acc: 0.966750\n",
      "Test Loss: 0.002014, Acc: 0.964500\n",
      "epoch 28\n",
      "Train Loss: 0.001969, Acc: 0.965317\n",
      "Test Loss: 0.001975, Acc: 0.965900\n",
      "epoch 29\n",
      "Train Loss: 0.001942, Acc: 0.966617\n",
      "Test Loss: 0.001947, Acc: 0.965900\n",
      "epoch 30\n",
      "Train Loss: 0.001937, Acc: 0.966417\n",
      "Test Loss: 0.001899, Acc: 0.967200\n",
      "epoch 31\n",
      "Train Loss: 0.001961, Acc: 0.966217\n",
      "Test Loss: 0.001985, Acc: 0.964500\n",
      "epoch 32\n",
      "Train Loss: 0.001950, Acc: 0.966150\n",
      "Test Loss: 0.002342, Acc: 0.958000\n",
      "epoch 33\n",
      "Train Loss: 0.001951, Acc: 0.966133\n",
      "Test Loss: 0.001847, Acc: 0.968700\n",
      "epoch 34\n",
      "Train Loss: 0.001946, Acc: 0.965583\n",
      "Test Loss: 0.001900, Acc: 0.965900\n",
      "epoch 35\n",
      "Train Loss: 0.001935, Acc: 0.967283\n",
      "Test Loss: 0.001898, Acc: 0.967400\n",
      "epoch 36\n",
      "Train Loss: 0.001955, Acc: 0.966233\n",
      "Test Loss: 0.001903, Acc: 0.966700\n",
      "epoch 37\n",
      "Train Loss: 0.001953, Acc: 0.966133\n",
      "Test Loss: 0.002070, Acc: 0.963800\n",
      "epoch 38\n",
      "Train Loss: 0.001939, Acc: 0.966150\n",
      "Test Loss: 0.001996, Acc: 0.962200\n",
      "epoch 39\n",
      "Train Loss: 0.001932, Acc: 0.966033\n",
      "Test Loss: 0.001978, Acc: 0.964000\n",
      "epoch 40\n",
      "Train Loss: 0.001941, Acc: 0.966550\n",
      "Test Loss: 0.001818, Acc: 0.967800\n",
      "epoch 41\n",
      "Train Loss: 0.001951, Acc: 0.966417\n",
      "Test Loss: 0.001948, Acc: 0.966000\n",
      "epoch 42\n",
      "Train Loss: 0.001960, Acc: 0.965533\n",
      "Test Loss: 0.001857, Acc: 0.967500\n",
      "epoch 43\n",
      "Train Loss: 0.001927, Acc: 0.966850\n",
      "Test Loss: 0.001948, Acc: 0.966000\n",
      "epoch 44\n",
      "Train Loss: 0.001940, Acc: 0.966650\n",
      "Test Loss: 0.002006, Acc: 0.961500\n",
      "epoch 45\n",
      "Train Loss: 0.001942, Acc: 0.966483\n",
      "Test Loss: 0.001773, Acc: 0.968800\n",
      "epoch 46\n",
      "Train Loss: 0.001949, Acc: 0.966617\n",
      "Test Loss: 0.001839, Acc: 0.968100\n",
      "epoch 47\n",
      "Train Loss: 0.001960, Acc: 0.965800\n",
      "Test Loss: 0.001839, Acc: 0.968200\n",
      "epoch 48\n",
      "Train Loss: 0.001937, Acc: 0.966367\n",
      "Test Loss: 0.002006, Acc: 0.966300\n",
      "epoch 49\n",
      "Train Loss: 0.001948, Acc: 0.966100\n",
      "Test Loss: 0.001990, Acc: 0.963700\n",
      "epoch 50\n",
      "Train Loss: 0.001932, Acc: 0.966717\n",
      "Test Loss: 0.001954, Acc: 0.965900\n",
      "epoch 51\n",
      "Train Loss: 0.001943, Acc: 0.966350\n",
      "Test Loss: 0.001900, Acc: 0.965100\n",
      "epoch 52\n",
      "Train Loss: 0.001936, Acc: 0.967267\n",
      "Test Loss: 0.001856, Acc: 0.967100\n",
      "epoch 53\n",
      "Train Loss: 0.001931, Acc: 0.966917\n",
      "Test Loss: 0.002004, Acc: 0.965300\n",
      "epoch 54\n",
      "Train Loss: 0.001924, Acc: 0.966283\n",
      "Test Loss: 0.001920, Acc: 0.965200\n",
      "epoch 55\n",
      "Train Loss: 0.001938, Acc: 0.967033\n",
      "Test Loss: 0.001875, Acc: 0.965600\n",
      "epoch 56\n",
      "Train Loss: 0.001923, Acc: 0.966900\n",
      "Test Loss: 0.001875, Acc: 0.965400\n",
      "epoch 57\n",
      "Train Loss: 0.001942, Acc: 0.966150\n",
      "Test Loss: 0.002016, Acc: 0.964700\n",
      "epoch 58\n",
      "Train Loss: 0.001923, Acc: 0.966683\n",
      "Test Loss: 0.001879, Acc: 0.967600\n",
      "epoch 59\n",
      "Train Loss: 0.001923, Acc: 0.966983\n",
      "Test Loss: 0.001957, Acc: 0.965100\n",
      "epoch 60\n",
      "Train Loss: 0.001956, Acc: 0.966367\n",
      "Test Loss: 0.001939, Acc: 0.964900\n",
      "epoch 61\n",
      "Train Loss: 0.001928, Acc: 0.966683\n",
      "Test Loss: 0.002043, Acc: 0.963100\n",
      "epoch 62\n",
      "Train Loss: 0.001937, Acc: 0.966833\n",
      "Test Loss: 0.001828, Acc: 0.968000\n",
      "epoch 63\n",
      "Train Loss: 0.001927, Acc: 0.966733\n",
      "Test Loss: 0.001830, Acc: 0.967400\n",
      "epoch 64\n",
      "Train Loss: 0.001935, Acc: 0.965867\n",
      "Test Loss: 0.001919, Acc: 0.965600\n",
      "epoch 65\n",
      "Train Loss: 0.001937, Acc: 0.967400\n",
      "Test Loss: 0.001847, Acc: 0.968000\n",
      "epoch 66\n",
      "Train Loss: 0.001933, Acc: 0.966717\n",
      "Test Loss: 0.002182, Acc: 0.961800\n",
      "epoch 67\n",
      "Train Loss: 0.001920, Acc: 0.967083\n",
      "Test Loss: 0.001889, Acc: 0.967000\n",
      "epoch 68\n",
      "Train Loss: 0.001934, Acc: 0.966100\n",
      "Test Loss: 0.001969, Acc: 0.964900\n",
      "epoch 69\n",
      "Train Loss: 0.001922, Acc: 0.966650\n",
      "Test Loss: 0.001842, Acc: 0.966500\n",
      "epoch 70\n",
      "Train Loss: 0.001928, Acc: 0.966633\n",
      "Test Loss: 0.002045, Acc: 0.963000\n",
      "epoch 71\n",
      "Train Loss: 0.001937, Acc: 0.966683\n",
      "Test Loss: 0.001968, Acc: 0.965000\n",
      "epoch 72\n",
      "Train Loss: 0.001946, Acc: 0.966100\n",
      "Test Loss: 0.002071, Acc: 0.961300\n",
      "epoch 73\n",
      "Train Loss: 0.001941, Acc: 0.967167\n",
      "Test Loss: 0.001991, Acc: 0.965000\n",
      "epoch 74\n",
      "Train Loss: 0.001934, Acc: 0.966850\n",
      "Test Loss: 0.001917, Acc: 0.964800\n",
      "epoch 75\n",
      "Train Loss: 0.001949, Acc: 0.966717\n",
      "Test Loss: 0.001887, Acc: 0.965200\n",
      "epoch 76\n",
      "Train Loss: 0.001928, Acc: 0.966050\n",
      "Test Loss: 0.001855, Acc: 0.968000\n",
      "epoch 77\n",
      "Train Loss: 0.001903, Acc: 0.967483\n",
      "Test Loss: 0.001854, Acc: 0.966600\n",
      "epoch 78\n",
      "Train Loss: 0.001934, Acc: 0.966517\n",
      "Test Loss: 0.001849, Acc: 0.967300\n",
      "epoch 79\n",
      "Train Loss: 0.001917, Acc: 0.966750\n",
      "Test Loss: 0.001807, Acc: 0.968700\n",
      "epoch 80\n",
      "Train Loss: 0.001919, Acc: 0.966350\n",
      "Test Loss: 0.001836, Acc: 0.966300\n",
      "epoch 81\n",
      "Train Loss: 0.001920, Acc: 0.967433\n",
      "Test Loss: 0.001927, Acc: 0.965000\n",
      "epoch 82\n",
      "Train Loss: 0.001918, Acc: 0.966750\n",
      "Test Loss: 0.001915, Acc: 0.965600\n",
      "epoch 83\n",
      "Train Loss: 0.001907, Acc: 0.967117\n",
      "Test Loss: 0.002045, Acc: 0.963600\n",
      "epoch 84\n",
      "Train Loss: 0.001909, Acc: 0.966967\n",
      "Test Loss: 0.001763, Acc: 0.968900\n",
      "epoch 85\n",
      "Train Loss: 0.001917, Acc: 0.967467\n",
      "Test Loss: 0.001912, Acc: 0.966000\n",
      "epoch 86\n",
      "Train Loss: 0.001916, Acc: 0.966667\n",
      "Test Loss: 0.001869, Acc: 0.966500\n",
      "epoch 87\n",
      "Train Loss: 0.001918, Acc: 0.967317\n",
      "Test Loss: 0.001946, Acc: 0.965700\n",
      "epoch 88\n",
      "Train Loss: 0.001918, Acc: 0.966867\n",
      "Test Loss: 0.002088, Acc: 0.960100\n",
      "epoch 89\n",
      "Train Loss: 0.001921, Acc: 0.967133\n",
      "Test Loss: 0.001935, Acc: 0.963500\n",
      "epoch 90\n",
      "Train Loss: 0.001918, Acc: 0.966533\n",
      "Test Loss: 0.001854, Acc: 0.967100\n",
      "epoch 91\n",
      "Train Loss: 0.001908, Acc: 0.967133\n",
      "Test Loss: 0.001873, Acc: 0.966800\n",
      "epoch 92\n",
      "Train Loss: 0.001924, Acc: 0.966367\n",
      "Test Loss: 0.002100, Acc: 0.961600\n",
      "epoch 93\n",
      "Train Loss: 0.001908, Acc: 0.966700\n",
      "Test Loss: 0.001852, Acc: 0.965500\n",
      "epoch 94\n",
      "Train Loss: 0.001903, Acc: 0.967833\n",
      "Test Loss: 0.001986, Acc: 0.966000\n",
      "epoch 95\n",
      "Train Loss: 0.001925, Acc: 0.967267\n",
      "Test Loss: 0.002036, Acc: 0.962700\n",
      "epoch 96\n",
      "Train Loss: 0.001918, Acc: 0.967233\n",
      "Test Loss: 0.001899, Acc: 0.967800\n",
      "epoch 97\n",
      "Train Loss: 0.001923, Acc: 0.966717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.001864, Acc: 0.964300\n",
      "epoch 98\n",
      "Train Loss: 0.001916, Acc: 0.966883\n",
      "Test Loss: 0.001864, Acc: 0.965800\n",
      "epoch 99\n",
      "Train Loss: 0.001904, Acc: 0.967483\n",
      "Test Loss: 0.002033, Acc: 0.964600\n",
      "epoch 100\n",
      "Train Loss: 0.001910, Acc: 0.966667\n",
      "Test Loss: 0.001805, Acc: 0.970000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data.dataloader as Data\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    './mnist', train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    './mnist', train=False, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "print(\"train_data:\", train_data.train_data.size())\n",
    "print(\"train_labels:\", train_data.train_labels.size())\n",
    "print(\"test_data:\", test_data.test_data.size())\n",
    "\n",
    "\n",
    "#超参数\n",
    "batch_size = 64\n",
    "Epoch = 100\n",
    "LR = 0.001  # 0.1, 0.001, 0.000001\n",
    "Weight_decay = 0.005\n",
    "\n",
    "#数据读取\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=batch_size)\n",
    "\n",
    "#定义模型\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear_0 = torch.nn.Linear(784, 500)\n",
    "        self.linear_1 = torch.nn.Linear(500, 128)\n",
    "        self.linear_2 = torch.nn.Linear(128, 50)\n",
    "        self.linear_3 = torch.nn.Linear(50, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_0(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.act(x)\n",
    "        out = self.linear_3(x)\n",
    "        return out\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "#初始化模型，优化器\n",
    "model = Net()\n",
    "print(model)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LR,weight_decay=Weight_decay)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#训练，测试\n",
    "for epoch in range(Epoch):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    cur = 1\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        if cur == 1 and epoch == 0:\n",
    "            print(batch_x.size())\n",
    "            print(batch_y.size())\n",
    "            cur += 1\n",
    "        batch_x = batch_x.view(batch_x.size()[0],-1)\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        train_loss += loss.item()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        train_correct = (pred == batch_y).sum()\n",
    "        train_acc += train_correct.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Train Loss: {:.6f}, Acc: {:.6f}'.format(train_loss / (len(\n",
    "        train_data)), train_acc / (len(train_data))))\n",
    "\n",
    "    # evaluation--------------------------------\n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x = batch_x.view(batch_x.size()[0],-1)\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        eval_loss += loss.item()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        num_correct = (pred == batch_y).sum()\n",
    "        eval_acc += num_correct.item()\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "        test_data)), eval_acc / (len(test_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9018a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
